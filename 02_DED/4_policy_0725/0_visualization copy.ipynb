{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58c19a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda is available\")\n",
    "else:\n",
    "    print(\"cuda is NOT available\")\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from moving_average import moving_average_1d\n",
    "\n",
    "import importlib\n",
    "import policy\n",
    "importlib.reload(policy)\n",
    "from policy import PolicyNN\n",
    "\n",
    "from nn_functions import surrogate\n",
    "\n",
    "import sys\n",
    "sys.path.append('../1_model')\n",
    "from TiDE import TideModule, quantile_loss  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a70801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Load model\n",
    "with open('TiDE_params_single_track_square_MV_temp_depth_less_cov_0915_w50_p50.pkl', 'rb') as file:\n",
    "    nominal_params = pickle.load(file)\n",
    "\n",
    "TiDE = nominal_params['model'].to(device)\n",
    "total_params = sum(p.numel() for p in TiDE.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d927345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyNN(\n",
       "  (input_layer): Linear(in_features=600, out_features=1024, bias=True)\n",
       "  (input_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (norm_layers): ModuleList(\n",
       "    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=1024, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# ── Constants ─────────────────────────────────────\n",
    "INPUT_DATA_DIR = \"data\"\n",
    "SIM_DIR_NAME = \"single_track_square\"\n",
    "BASE_LASER_FILE_DIR = \"laser_power_profiles/csv\"\n",
    "CLOUD_TARGET_BASE_PATH = \"result\"\n",
    "solidus_temp = 1600\n",
    "window = 50\n",
    "sim_interval = 5\n",
    "init_runs = 50\n",
    "P = 50\n",
    "\n",
    "model_path = \"/home/ftk3187/github/DPC_research/02_DED/4_policy_0725/trainresults/policy_model_discreteshift_3L_1024H_s1_c0_case19.pth\"\n",
    "\n",
    "# ── Load model ─────────────────────────────────────\n",
    "model = PolicyNN(\n",
    "    past_input_dim=6,\n",
    "    future_input_dim=6,\n",
    "    output_dim=1,\n",
    "    p=P,\n",
    "    window=window,\n",
    "    hidden_dim=1024,\n",
    "    n_layers=3,\n",
    "    dropout_p=0.1\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7372029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from pickle import dump\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "from GAMMA_obj_temp_depth import GAMMA_obj\n",
    "\n",
    "import importlib\n",
    "import policy\n",
    "importlib.reload(policy)\n",
    "from policy import PolicyNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49cd9e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values from user\n",
    "x_min = torch.tensor([[0.0, 0.75, 0.75, 504.26]], dtype=torch.float32).to(device)\n",
    "x_max = torch.tensor([[7.5, 20.0, 20.0, 732.298]], dtype=torch.float32).to(device)\n",
    "\n",
    "y_min = torch.tensor([[436.608, -0.559]], dtype=torch.float32).to(device)\n",
    "y_max = torch.tensor([[4509.855, 0.551]], dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "def normalize_x(x, dim_id):\n",
    "    x_min_selected = x_min[0, dim_id]\n",
    "    x_max_selected = x_max[0, dim_id]\n",
    "    return 2 * (x - x_min_selected) / (x_max_selected - x_min_selected) - 1\n",
    "\n",
    "def inverse_normalize_x(x_norm, dim_id):\n",
    "    x_min_selected = x_min[0, dim_id]\n",
    "    x_max_selected = x_max[0, dim_id]\n",
    "    return 0.5 * (x_norm + 1) * (x_max_selected - x_min_selected) + x_min_selected\n",
    "\n",
    "def normalize_y(y, dim_id):\n",
    "    y_min_selected = y_min[0, dim_id]\n",
    "    y_max_selected = y_max[0, dim_id]\n",
    "    return 2 * (y - y_min_selected) / (y_max_selected - y_min_selected) - 1\n",
    "\n",
    "def inverse_normalize_y(y_norm, dim_id):\n",
    "    y_min_selected = y_min[0, dim_id]\n",
    "    y_max_selected = y_max[0, dim_id]\n",
    "    return 0.5 * (y_norm + 1) * (y_max_selected - y_min_selected) + y_min_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bd55a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "\n",
    "def simulate_policy_horizon_for_visualization(GAMMA_obj, policy_model, TiDE, P, window):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        - tide_temp_pred: [50]\n",
    "        - tide_depth_pred: [50]\n",
    "        - gamma_temp_sim: [50]\n",
    "        - gamma_depth_sim: [50]\n",
    "    \"\"\"\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    # 1. Policy Input 생성 (정책 모델용 → normalized)\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    mp_temp_ref = GAMMA_obj.ref[GAMMA_obj.MPC_counter:GAMMA_obj.MPC_counter + P]\n",
    "    mp_temp_ref_t = torch.tensor(mp_temp_ref, dtype=torch.float32, device=device).reshape(1, P, 1)\n",
    "\n",
    "    mp_temp_past_t = GAMMA_obj.x_past.T.unsqueeze(0).to(device)  # [1, 50, 2]\n",
    "    laser_past_t = GAMMA_obj.u_past.view(1, -1, 1).to(device)     # [1, 50, 1]\n",
    "\n",
    "    fix_cov_past = GAMMA_obj.fix_cov_all[GAMMA_obj.MPC_counter - window:GAMMA_obj.MPC_counter, :]\n",
    "    fix_cov_future = GAMMA_obj.fix_cov_all[GAMMA_obj.MPC_counter:GAMMA_obj.MPC_counter + P, :]\n",
    "\n",
    "    fix_cov_past_t = torch.tensor(fix_cov_past, dtype=torch.float32, device=device).unsqueeze(0)  # [1, 50, 3]\n",
    "    fix_cov_future_t = torch.tensor(fix_cov_future, dtype=torch.float32, device=device).unsqueeze(0)  # [1, 50, 3]\n",
    "\n",
    "    # Normalize for policy model\n",
    "    fix_cov_past_s = normalize_x(fix_cov_past_t, dim_id=[0, 1, 2])\n",
    "    fix_cov_future_s = normalize_x(fix_cov_future_t, dim_id=[0, 1, 2])\n",
    "    laser_past_s = normalize_x(laser_past_t, dim_id=[3])\n",
    "    mp_temp_past_s = normalize_y(mp_temp_past_t, dim_id=[0, 1])\n",
    "    mp_temp_ref_s = normalize_y(mp_temp_ref_t, dim_id=[0])[:, :, 0].unsqueeze(-1)\n",
    "\n",
    "    depth_lower_const = 0.1423\n",
    "    depth_upper_const = 0.4126\n",
    "    y_const_s = torch.tensor([[depth_lower_const, depth_upper_const]] * P,\n",
    "                             dtype=torch.float32, device=device).reshape(1, P, 2)\n",
    "\n",
    "    policy_in_past = torch.cat((fix_cov_past_s, laser_past_s, mp_temp_past_s), dim=2)  # [1, 50, 6]\n",
    "    policy_in_future = torch.cat((fix_cov_future_s, mp_temp_ref_s, y_const_s), dim=2)  # [1, 50, 6]\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    # 2. Policy inference → u_pred (normalized) & u_seq (denorm)\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    with torch.no_grad():\n",
    "        u_pred = policy_model((policy_in_past, policy_in_future))  # [1, 50, 1]\n",
    "        u_seq_norm = u_pred[0]  # [50, 1]\n",
    "        u_seq = inverse_normalize_x(u_seq_norm, dim_id=[3])  # [50, 1]\n",
    "        \n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    # 3. TiDE 예측 수행 (비정책 입력 형식: unnormalized + reordered)\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    # TiDE past_cov: [y_past, x_past] → [1, 50, 6]\n",
    "    past_cov = torch.cat((mp_temp_past_s, fix_cov_past_s), dim=2)\n",
    "\n",
    "    # TiDE future_cov: [x_future, u_pred] → [1, 50, 4]\n",
    "    future_cov = torch.cat((fix_cov_future_s, u_pred.to(device)), dim=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tide_out = TiDE((past_cov, future_cov, None))  # [1, 50, quantile, 2]\n",
    "        tide_out_med = tide_out[:, :, :, 1].squeeze(0).cpu().numpy()  # [50, 2]\n",
    "        tide_temp_pred = inverse_normalize_y(torch.tensor(tide_out_med[:, 0], device=device), dim_id=[0])\n",
    "        tide_depth_pred = inverse_normalize_y(torch.tensor(tide_out_med[:, 1], device=device), dim_id=[1])\n",
    "\n",
    "\n",
    "   # ─────────────────────────────────────────────────────────────\n",
    "    # ── 4. GAMMA 시뮬레이션 (cumulative update) ────────────\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    gamma_temp_sim = []\n",
    "    gamma_depth_sim = []\n",
    "\n",
    "    gamma_copy = copy.deepcopy(GAMMA_obj)\n",
    "\n",
    "    # ✅ 명시적 초기화 (GAMMA 내부 상태 재설정)\n",
    "    gamma_copy.x_sys_current = gamma_copy.x_past[:, -1].reshape(2, 1)\n",
    "    gamma_copy.x_hat_current = gamma_copy.x_sys_current.flatten()\n",
    "    gamma_copy.MPC_counter = window\n",
    "    gamma_copy.x_past_save = gamma_copy.x_past.T.clone()\n",
    "    gamma_copy.u_past_save = gamma_copy.u_past.view(-1, 1).clone()\n",
    "\n",
    "    for i in range(P):\n",
    "        u_val = float(u_seq[i].item())\n",
    "\n",
    "        # 한 스텝 시뮬레이션 실행\n",
    "        x_t, d_t = gamma_copy.run_sim_interval(u_val)\n",
    "\n",
    "\n",
    "        # 출력 저장\n",
    "        gamma_temp_sim.append(x_t)\n",
    "        gamma_depth_sim.append(d_t)\n",
    "\n",
    "        # 시계열 업데이트\n",
    "        gamma_copy.x_past[:, :-1] = gamma_copy.x_past[:, 1:]\n",
    "        gamma_copy.x_past[0, -1] = x_t\n",
    "        gamma_copy.x_past[1, -1] = d_t\n",
    "\n",
    "        gamma_copy.u_past[:-1] = gamma_copy.u_past[1:].clone()\n",
    "        gamma_copy.u_past[-1] = u_val\n",
    "\n",
    "        # 상태 변수 업데이트\n",
    "        gamma_copy.x_hat_current = torch.tensor([x_t, d_t], device=device)\n",
    "        gamma_copy.x_sys_current = torch.tensor([[x_t], [d_t]], device=device)\n",
    "        gamma_copy.MPC_counter += 1\n",
    "\n",
    "        # 전체 시계열 기록도 업데이트 (plot 대비)\n",
    "        new_state = torch.tensor([[x_t, d_t]], device=gamma_copy.x_past_save.device)\n",
    "        gamma_copy.x_past_save = torch.cat((gamma_copy.x_past_save, new_state), dim=0)\n",
    "\n",
    "        new_u = torch.tensor([[u_val]], device=gamma_copy.u_past_save.device)\n",
    "        gamma_copy.u_past_save = torch.cat((gamma_copy.u_past_save, new_u), dim=0)\n",
    "\n",
    "\n",
    "    return (\n",
    "        tide_temp_pred.cpu().numpy(),   # [50]\n",
    "        tide_depth_pred.cpu().numpy(),  # [50]\n",
    "        np.array(gamma_temp_sim),       # [50]\n",
    "        np.array(gamma_depth_sim),      # [50]\n",
    "        u_seq.cpu().numpy()             # [50, 1]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed3fd92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_tide_vs_gamma_stepwise(\n",
    "    step_idx,\n",
    "    GAMMA_obj,\n",
    "    tide_temp,\n",
    "    tide_depth,\n",
    "    gamma_temp,\n",
    "    gamma_depth,\n",
    "    u_seq,\n",
    "    P=50\n",
    "):\n",
    "    time_steps = np.arange(step_idx, step_idx + P)\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 7), sharex=True)\n",
    "\n",
    "    # ── Temperature Plot ──────────────────────────────\n",
    "    axs[0].plot(time_steps, tide_temp, label=\"TiDE Temp\", linestyle='--', marker='o')\n",
    "    axs[0].plot(time_steps, gamma_temp, label=\"GAMMA Temp\", linestyle='-', marker='x')\n",
    "    axs[0].set_ylabel(\"Melt Pool Temp (K)\")\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # ── Depth Plot ────────────────────────────────────\n",
    "    axs[1].plot(time_steps, tide_depth, label=\"TiDE Depth\", linestyle='--', marker='o')\n",
    "    axs[1].plot(time_steps, gamma_depth, label=\"GAMMA Depth\", linestyle='-', marker='x')\n",
    "    axs[1].set_ylabel(\"Melt Pool Depth (mm)\")\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    # ── Laser Power Input ─────────────────────────────\n",
    "    axs[2].plot(time_steps, u_seq.squeeze(), label=\"Policy Laser Power\", color='green', marker='.')\n",
    "    axs[2].set_ylabel(\"Laser Power\")\n",
    "    axs[2].set_xlabel(\"Timestep\")\n",
    "    axs[2].legend()\n",
    "    axs[2].grid(True)\n",
    "\n",
    "    fig.suptitle(f\"Step {step_idx} → {step_idx + P - 1}: TiDE vs GAMMA\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28e443ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# 레이저 번호 설정\n",
    "laser_power_number = 15\n",
    "\n",
    "# 원본 데이터 불러오기\n",
    "csv_path = f\"/home/ftk3187/github/DPC_research/02_DED/4_policy_0725/split_by_laser_power_number/laser_power_number_{laser_power_number}.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 고정 공변량\n",
    "loc_Z  = df[\"Z\"].to_numpy().reshape(-1, 1)\n",
    "dist_X = df[\"Dist_to_nearest_X\"].to_numpy().reshape(-1, 1)\n",
    "dist_Y = df[\"Dist_to_nearest_Y\"].to_numpy().reshape(-1, 1)\n",
    "fix_covariates = torch.tensor(np.concatenate((loc_Z, dist_X, dist_Y), axis=1), dtype=torch.float32, device=device)\n",
    "\n",
    "# 레이저 파워 시퀀스\n",
    "laser_power_ref = torch.tensor(df[\"Laser_power\"].to_numpy().reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "\n",
    "# ⛳ melt pool temperature → smoothing → tensor\n",
    "mp_temp_raw = df[\"melt_pool_temperature\"].to_numpy()\n",
    "mp_temp_smooth = copy.deepcopy(mp_temp_raw)\n",
    "mp_temp_smooth[1:-2] = (mp_temp_raw[:-3] + mp_temp_raw[1:-2] + mp_temp_raw[2:-1] + mp_temp_raw[3:]) / 4\n",
    "mp_temp_ref = torch.tensor(mp_temp_smooth, dtype=torch.float32, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61b4e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:05<00:00, 42.93it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Step 2: 시뮬레이션 루프\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_steps \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# 정책 기반 예측 (50-step u_seq 예측)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     _, _, _, _, u_seq \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_policy_horizon_for_visualization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mGAMMA_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTiDE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTiDE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# u_seq[0] 만 적용 → 1 step 실행\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     u_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(u_seq[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[15], line 62\u001b[0m, in \u001b[0;36msimulate_policy_horizon_for_visualization\u001b[0;34m(GAMMA_obj, policy_model, TiDE, P, window)\u001b[0m\n\u001b[1;32m     59\u001b[0m future_cov \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((fix_cov_future_s, u_pred\u001b[38;5;241m.\u001b[39mto(device)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 62\u001b[0m     tide_out \u001b[38;5;241m=\u001b[39m \u001b[43mTiDE\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_cov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_cov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [1, 50, quantile, 2]\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     tide_out_med \u001b[38;5;241m=\u001b[39m tide_out[:, :, :, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# [50, 2]\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     tide_temp_pred \u001b[38;5;241m=\u001b[39m inverse_normalize_y(torch\u001b[38;5;241m.\u001b[39mtensor(tide_out_med[:, \u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice), dim_id\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/github/DPC_research/02_DED/4_policy_0725/TiDE.py:372\u001b[0m, in \u001b[0;36mTideModule.forward\u001b[0;34m(self, x_in)\u001b[0m\n\u001b[1;32m    365\u001b[0m     x_dynamic_future_covariates \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    366\u001b[0m         [x[:,:,\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture_cov_dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture_cov_dim :,], x_future_covariates,],\n\u001b[1;32m    367\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    368\u001b[0m     ) \u001b[38;5;66;03m# shape (batch, input_chunck_length + output_chunck_length, future_cov_dim)\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_width_future:\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;66;03m# project input features across all input and output time steps; feed them into the feature projection residual block. \u001b[39;00m\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;66;03m# the output shape should be (batchj, L+H, temporal_width_future)\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m         x_dynamic_future_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuture_cov_projection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx_dynamic_future_covariates\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     x_dynamic_future_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/github/DPC_research/02_DED/4_policy_0725/TiDE.py:132\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip(x)\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# layer normalization\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "max_steps = 20\n",
    "GAMMA_obj = GAMMA_obj(\n",
    "    INPUT_DATA_DIR=\"data\",\n",
    "    SIM_DIR_NAME=\"single_track_square\",\n",
    "    BASE_LASER_FILE_DIR=\"laser_power_profiles/csv\",\n",
    "    CLOUD_TARGET_BASE_PATH=\"result\",\n",
    "    solidus_temp=solidus_temp,\n",
    "    window=window,\n",
    "    init_runs=init_runs,\n",
    "    sim_interval=sim_interval,\n",
    "    laser_power_number=laser_power_number\n",
    ")\n",
    "\n",
    "# Step 1: 초기 상태 세팅\n",
    "init_avg = torch.tensor(GAMMA_obj.run_initial_steps(), dtype=torch.float32, device=device)[:, -window:]\n",
    "GAMMA_obj.ref = mp_temp_ref.clone()\n",
    "GAMMA_obj.fix_cov_all = fix_covariates.clone()\n",
    "GAMMA_obj.x_past = init_avg.clone()\n",
    "GAMMA_obj.u_past = laser_power_ref[:window].clone()\n",
    "GAMMA_obj.x_past_save = GAMMA_obj.x_past.T.clone()\n",
    "GAMMA_obj.u_past_save = GAMMA_obj.u_past.view(-1, 1).clone()\n",
    "GAMMA_obj.MPC_counter = window\n",
    "GAMMA_obj.x_hat_current = GAMMA_obj.x_past[:, -1]\n",
    "GAMMA_obj.x_sys_current = GAMMA_obj.x_hat_current.reshape(2, 1)\n",
    "\n",
    "# Step 2: 시뮬레이션 루프\n",
    "for step in range(1, max_steps + 1):\n",
    "    # 정책 기반 예측 (50-step u_seq 예측)\n",
    "    _, _, _, _, u_seq = simulate_policy_horizon_for_visualization(\n",
    "        GAMMA_obj, policy_model=model, TiDE=TiDE, P=P, window=window\n",
    "    )\n",
    "\n",
    "    # u_seq[0] 만 적용 → 1 step 실행\n",
    "    u_val = float(u_seq[0].item())\n",
    "    x_t, d_t = GAMMA_obj.run_sim_interval(u_val)\n",
    "\n",
    "    # 시계열 업데이트 (한 칸 shift)\n",
    "    GAMMA_obj.x_past[:, :-1] = GAMMA_obj.x_past[:, 1:]\n",
    "    GAMMA_obj.x_past[0, -1], GAMMA_obj.x_past[1, -1] = x_t, d_t\n",
    "    GAMMA_obj.u_past[:-1] = GAMMA_obj.u_past[1:].clone()\n",
    "    GAMMA_obj.u_past[-1] = u_val\n",
    "    GAMMA_obj.x_hat_current = torch.tensor([x_t, d_t], device=device)\n",
    "    GAMMA_obj.x_sys_current = GAMMA_obj.x_hat_current.reshape(2, 1)\n",
    "    GAMMA_obj.MPC_counter += 1\n",
    "\n",
    "    # Step 3: 마지막 step 에서만 전체 시각화 수행\n",
    "    if step == max_steps:\n",
    "        tide_temp, tide_depth, _, _, u_seq_final = simulate_policy_horizon_for_visualization(\n",
    "            GAMMA_obj, policy_model=model, TiDE=TiDE, P=P, window=window\n",
    "        )\n",
    "\n",
    "        gamma_temp_sim, gamma_depth_sim = [], []\n",
    "        for i in range(P):\n",
    "            u_val = float(u_seq_final[i].item())\n",
    "            x_t, d_t = GAMMA_obj.run_sim_interval(u_val)\n",
    "            gamma_temp_sim.append(x_t)\n",
    "            gamma_depth_sim.append(d_t)\n",
    "\n",
    "            # 상태 업데이트\n",
    "            GAMMA_obj.x_past[:, :-1] = GAMMA_obj.x_past[:, 1:]\n",
    "            GAMMA_obj.x_past[0, -1], GAMMA_obj.x_past[1, -1] = x_t, d_t\n",
    "            GAMMA_obj.u_past[:-1] = GAMMA_obj.u_past[1:].clone()\n",
    "            GAMMA_obj.u_past[-1] = u_val\n",
    "            GAMMA_obj.x_hat_current = torch.tensor([x_t, d_t], device=device)\n",
    "            GAMMA_obj.x_sys_current = GAMMA_obj.x_hat_current.reshape(2, 1)\n",
    "            GAMMA_obj.MPC_counter += 1\n",
    "\n",
    "            if step % 5 == 0:\n",
    "                print(f\"[Step {step}] u: {u_val:.1f}, pred temp: {tide_temp[0]:.1f}, sim temp: {x_t:.1f}\")\n",
    "\n",
    "        # 시각화\n",
    "        plot_tide_vs_gamma_stepwise(\n",
    "            step_idx=GAMMA_obj.MPC_counter,\n",
    "            GAMMA_obj=GAMMA_obj,\n",
    "            tide_temp=tide_temp,\n",
    "            tide_depth=tide_depth,\n",
    "            gamma_temp=np.array(gamma_temp_sim),\n",
    "            gamma_depth=np.array(gamma_depth_sim),\n",
    "            u_seq=u_seq_final,\n",
    "            P=P\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa17ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
