{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa2cc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Tuple\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from pickle import dump\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda is available\")\n",
    "else:\n",
    "    print(\"cuda is NOT available\")\n",
    "\n",
    "\n",
    "import shutil\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "from nn_functions import surrogate\n",
    "from moving_average import moving_average_1d\n",
    "import copy\n",
    "from GAMMA_obj_temp_depth import GAMMA_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4455d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyNN(\n",
       "  (input_layer): Linear(in_features=1400, out_features=1024, bias=True)\n",
       "  (input_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (norm_layers): ModuleList(\n",
       "    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=1024, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from policy import PolicyNN\n",
    "model = PolicyNN(\n",
    "    past_input_dim=14,\n",
    "    future_input_dim=14,\n",
    "    output_dim=1,\n",
    "    p=50,\n",
    "    window=50,\n",
    "    hidden_dim=1024,\n",
    "    n_layers=3,\n",
    "    dropout_p=0.1\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"/home/ftk3187/github/DPC_research/02_DED/5_policy_0728_onehotencoding/trainresults/policy_model_3L_1024H_s0_c0.pth\", map_location=\"cpu\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea727d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec0ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:05<00:00, 46.32it/s]\n"
     ]
    }
   ],
   "source": [
    "INPUT_DATA_DIR = \"data\"\n",
    "SIM_DIR_NAME = \"single_track_square\"\n",
    "BASE_LASER_FILE_DIR = \"laser_power_profiles/csv\"\n",
    "CLOUD_TARGET_BASE_PATH = \"result\"\n",
    "solidus_temp = 1600\n",
    "window = 50\n",
    "sim_interval = 5\n",
    "init_runs = 50 #50 \n",
    "\n",
    "GAMMA_class = GAMMA_obj(INPUT_DATA_DIR, SIM_DIR_NAME, BASE_LASER_FILE_DIR, CLOUD_TARGET_BASE_PATH, solidus_temp, window, init_runs, sim_interval, laser_power_number=1)\n",
    "init_avg = GAMMA_class.run_initial_steps()\n",
    "init_avg = torch.tensor(init_avg,dtype=torch.float32)[:,-window:] # shape = [2,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52950edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_print = pd.read_csv('single_track_ref.csv')\n",
    "\n",
    "loc_X_list = df_one_print[\"X\"].to_numpy().reshape(-1,1)\n",
    "loc_Y_list = df_one_print[\"Y\"].to_numpy().reshape(-1,1)\n",
    "loc_Z_list = df_one_print[\"Z\"].to_numpy().reshape(-1,1)\n",
    "dist_X_list = df_one_print[\"Dist_to_nearest_X\"].to_numpy().reshape(-1,1)\n",
    "dist_Y_list = df_one_print[\"Dist_to_nearest_Y\"].to_numpy().reshape(-1,1)\n",
    "scan_spd_list = df_one_print[\"scanning_speed\"].to_numpy().reshape(-1,1)\n",
    "\n",
    "# laser on/off indicator\n",
    "laser_on_off = df_one_print[\"laser_power_number\"].to_numpy().reshape(-1,1)\n",
    "\n",
    "# laser power\n",
    "laser_power_ref = torch.tensor(df_one_print[\"Laser_power\"].to_numpy().reshape(-1,1),dtype=torch.float32)\n",
    "laser_power_past = laser_power_ref[:window]\n",
    "\n",
    "# fix_covariates = torch.tensor(np.concatenate((loc_X_list,loc_Y_list,loc_Z_list,dist_X_list,dist_Y_list,scan_spd_list, laser_on_off),axis=1),dtype=torch.float32)\n",
    "fix_covariates = torch.tensor(np.concatenate((loc_Z_list,dist_X_list,dist_Y_list),axis=1),dtype=torch.float32)\n",
    "\n",
    "# temporary ref\n",
    "# apply moving average for mp temp\n",
    "mp_temp_raw = df_one_print[\"melt_pool_temperature\"].to_numpy()\n",
    "mp_temp_mv = moving_average_1d(mp_temp_raw,4)\n",
    "mp_temp = copy.deepcopy(mp_temp_raw)\n",
    "mp_temp[1:-2] = mp_temp_mv\n",
    "mp_temp = mp_temp\n",
    "\n",
    "mp_temp_ref = torch.tensor(mp_temp,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# values from user\n",
    "x_min = torch.tensor([[0.0, 0.75, 0.75, 504.26]], dtype=torch.float32).to(device)\n",
    "x_max = torch.tensor([[7.5, 20.0, 20.0, 732.298]], dtype=torch.float32).to(device)\n",
    "\n",
    "y_min = torch.tensor([[436.608, -0.559]], dtype=torch.float32).to(device)\n",
    "y_max = torch.tensor([[4509.855, 0.551]], dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ce7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_x(x, dim_id):\n",
    "    x_min_selected = x_min[0, dim_id]\n",
    "    x_max_selected = x_max[0, dim_id]\n",
    "    return 2 * (x - x_min_selected) / (x_max_selected - x_min_selected) - 1\n",
    "\n",
    "def inverse_normalize_x(x_norm, dim_id):\n",
    "    x_min_selected = x_min[0, dim_id]\n",
    "    x_max_selected = x_max[0, dim_id]\n",
    "    return 0.5 * (x_norm + 1) * (x_max_selected - x_min_selected) + x_min_selected\n",
    "\n",
    "def normalize_y(y, dim_id):\n",
    "    y_min_selected = y_min[0, dim_id]\n",
    "    y_max_selected = y_max[0, dim_id]\n",
    "    return 2 * (y - y_min_selected) / (y_max_selected - y_min_selected) - 1\n",
    "\n",
    "def inverse_normalize_y(y_norm, dim_id):\n",
    "    y_min_selected = y_min[0, dim_id]\n",
    "    y_max_selected = y_max[0, dim_id]\n",
    "    return 0.5 * (y_norm + 1) * (y_max_selected - y_min_selected) + y_min_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c693cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique z indices assigned: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "loc_Z = df_one_print[\"Z\"].to_numpy().reshape(-1,1)\n",
    "z_s = loc_Z\n",
    "\n",
    "# 1. Define Z bin centers (예: 0.75 간격으로 10개 구간)\n",
    "z_bin_edges = np.arange(0.75, 7.5 + 0.75, 0.75)  # [0.75, 1.5, ..., 7.5]\n",
    "num_bins = len(z_bin_edges)\n",
    "\n",
    "# 2. Define function to assign index based on nearest bin\n",
    "def get_z_index(z_value):\n",
    "    distances = np.abs(z_bin_edges - z_value)\n",
    "    return int(np.argmin(distances))\n",
    "\n",
    "# 3. Apply to full z_s array (shape: [N, 1])\n",
    "z_indices = np.array([get_z_index(float(z[0])) for z in z_s], dtype=np.int64)\n",
    "\n",
    "# (Optional) Check unique indices for sanity\n",
    "print(\"Unique z indices assigned:\", np.unique(z_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48581acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_x(x, dim_id):\n",
    "    x_min_selected = x_min[0, dim_id]\n",
    "    x_max_selected = x_max[0, dim_id]\n",
    "    return 2 * (x - x_min_selected) / (x_max_selected - x_min_selected) - 1\n",
    "\n",
    "def inverse_normalize_x(x_norm, dim_id):\n",
    "    x_min_selected = x_min[0, dim_id]\n",
    "    x_max_selected = x_max[0, dim_id]\n",
    "    return 0.5 * (x_norm + 1) * (x_max_selected - x_min_selected) + x_min_selected\n",
    "\n",
    "def normalize_y(y, dim_id):\n",
    "    y_min_selected = y_min[0, dim_id]\n",
    "    y_max_selected = y_max[0, dim_id]\n",
    "    return 2 * (y - y_min_selected) / (y_max_selected - y_min_selected) - 1\n",
    "\n",
    "def inverse_normalize_y(y_norm, dim_id):\n",
    "    y_min_selected = y_min[0, dim_id]\n",
    "    y_max_selected = y_max[0, dim_id]\n",
    "    return 0.5 * (y_norm + 1) * (y_max_selected - y_min_selected) + y_min_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_step_policy(GAMMA_obj, policy_model, P, window):\n",
    "    num_bins = 10\n",
    "    z_bin_edges = np.arange(0.75, 7.5 + 0.75, 0.75)\n",
    "\n",
    "    def get_z_index(z_value):\n",
    "        return int(np.argmin(np.abs(z_bin_edges - z_value)))\n",
    "\n",
    "    # Reference temperature\n",
    "    mp_temp_ref = GAMMA_obj.ref[GAMMA_obj.MPC_counter:GAMMA_obj.MPC_counter + P]\n",
    "    mp_temp_ref_t = torch.as_tensor(mp_temp_ref, dtype=torch.float32, device=device).reshape(1, P, 1)\n",
    "\n",
    "    # Past input (raw)\n",
    "    mp_temp_past_t = GAMMA_obj.x_past.T.unsqueeze(0).to(device)     # [1, 50, 2]\n",
    "    laser_past_t = GAMMA_obj.u_past.view(1, -1, 1).to(device)        # [1, 50, 1]\n",
    "    fix_cov_past = GAMMA_obj.fix_cov_all[GAMMA_obj.MPC_counter - window:GAMMA_obj.MPC_counter, :]\n",
    "    fix_cov_past_t = torch.as_tensor(fix_cov_past, dtype=torch.float32, device=device).unsqueeze(0)  # [1, 50, 3]\n",
    "\n",
    "    # Normalize past\n",
    "    fix_cov_past_s = normalize_x(fix_cov_past_t, dim_id=[0, 1, 2])\n",
    "    laser_past_s = normalize_x(laser_past_t, dim_id=[3])\n",
    "    mp_temp_past_s = normalize_y(mp_temp_past_t, dim_id=[0, 1])\n",
    "\n",
    "    # Z embedding (shared for past and future)\n",
    "    z_value = GAMMA_obj.z_all[GAMMA_obj.MPC_counter][0]\n",
    "    z_index = get_z_index(z_value)\n",
    "    z_onehot_vec = np.zeros(num_bins)\n",
    "    z_onehot_vec[z_index] = 1.0\n",
    "    z_onehot_vec = torch.tensor(z_onehot_vec, dtype=torch.float32, device=device).reshape(1, 1, num_bins)\n",
    "    z_onehot_past = z_onehot_vec.expand(1, window, num_bins)  # [1, 50, 10]\n",
    "    z_onehot_future = z_onehot_vec.expand(1, P, num_bins)     # [1, P, 10]\n",
    "\n",
    "    # Concatenate past input\n",
    "    policy_in_past = torch.cat((fix_cov_past_s, laser_past_s, mp_temp_past_s, z_onehot_past), dim=2)  # [1, 50, ?]\n",
    "\n",
    "    # Future covariates\n",
    "    fix_cov_future = GAMMA_obj.fix_cov_all[GAMMA_obj.MPC_counter:GAMMA_obj.MPC_counter + P, :]\n",
    "    fix_cov_future_t = torch.as_tensor(fix_cov_future, dtype=torch.float32, device=device).unsqueeze(0)  # [1, P, 3]\n",
    "    fix_cov_future_s = normalize_x(fix_cov_future_t, dim_id=[0, 1, 2])\n",
    "    mp_temp_ref_s = normalize_y(mp_temp_ref_t, dim_id=[0])[:, :, 0].unsqueeze(-1)\n",
    "\n",
    "    # Constraints\n",
    "    depth_lower_const = 0 * 0.1423\n",
    "    depth_upper_const = 0 * 0.4126\n",
    "    y_const_s = torch.tensor([[depth_lower_const, depth_upper_const]] * P, dtype=torch.float32, device=device).reshape(1, P, 2)\n",
    "\n",
    "    # Concatenate future input\n",
    "    policy_in_future = torch.cat((fix_cov_future_s, mp_temp_ref_s, y_const_s, z_onehot_future), dim=2)  # [1, P, ?]\n",
    "\n",
    "    # Inference\n",
    "    u_pred = policy_model((policy_in_past, policy_in_future))\n",
    "    u_first = u_pred[0, 0]\n",
    "    u_applied = float(inverse_normalize_x(u_first, dim_id=[3]))\n",
    "\n",
    "    # Simulate\n",
    "    x_current, depth_current = GAMMA_obj.run_sim_interval(u_applied)\n",
    "\n",
    "    # Update history\n",
    "    GAMMA_obj.x_past[:, :-1] = GAMMA_obj.x_past[:, 1:]\n",
    "    GAMMA_obj.x_past[0, -1] = x_current\n",
    "    GAMMA_obj.x_past[1, -1] = depth_current\n",
    "\n",
    "    GAMMA_obj.u_past[:-1] = GAMMA_obj.u_past[1:].clone()\n",
    "    GAMMA_obj.u_past[-1] = u_applied\n",
    "\n",
    "    # Save state\n",
    "    GAMMA_obj.x_hat_current = torch.tensor([x_current, depth_current], device=device)\n",
    "    GAMMA_obj.x_sys_current = torch.tensor([[x_current], [depth_current]], device=device)\n",
    "    GAMMA_obj.MPC_counter += 1\n",
    "\n",
    "    # Save to log\n",
    "    new_state = torch.tensor([[x_current, depth_current]], device=GAMMA_obj.x_past_save.device)\n",
    "    GAMMA_obj.x_past_save = torch.cat((GAMMA_obj.x_past_save, new_state), dim=0)\n",
    "\n",
    "    new_u = torch.tensor([[u_applied]], device=GAMMA_obj.u_past_save.device)\n",
    "    GAMMA_obj.u_past_save = torch.cat((GAMMA_obj.u_past_save, new_u), dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fig(MPC_GAMMA, N_step):\n",
    "    plt.figure(figsize=[12,10])\n",
    "    plt.subplot(3,1,1)\n",
    "    plt.plot(MPC_GAMMA.x_past_save[:N_step,0], label = \"GAMMA simulation\")\n",
    "    plt.plot(MPC_GAMMA.ref[:N_step], label=\"Reference\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.xlabel(\"MPC time step (0.0355 sec/iteration)\")\n",
    "    plt.ylabel(\"Melt Pool Temperature (k)\")\n",
    "\n",
    "    plt.subplot(3,1,2)\n",
    "    plt.plot(MPC_GAMMA.x_past_save[:N_step,1], label = \"GAMMA simulation\")\n",
    "    plt.plot(np.linspace(0,N_step,N_step),0.225*np.ones(N_step))\n",
    "    plt.plot(np.linspace(0,N_step,N_step),0.075*np.ones(N_step))\n",
    "    plt.xlabel(\"MPC time step (0.0355 sec/iteration)\")\n",
    "    plt.ylabel(\"Melt Pool Depth (mm)\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3,1,3)\n",
    "    plt.plot(MPC_GAMMA.u_past_save[:N_step])\n",
    "    plt.ylabel(\"Laser power (w)\")\n",
    "    plt.xlabel(\"MPC time step (0.0355 sec/iteration)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b5c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6295 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x600 and 1400x1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(N_step)):\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mrun_one_step_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGAMMA_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     27\u001b[0m         plot_fig(GAMMA_class, N_step)\n",
      "Cell \u001b[0;32mIn[20], line 43\u001b[0m, in \u001b[0;36mrun_one_step_policy\u001b[0;34m(GAMMA_obj, policy_model, P, window)\u001b[0m\n\u001b[1;32m     39\u001b[0m policy_in_future \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((fix_cov_future_s, mp_temp_ref_s, y_const_s), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# [1, P, 6]\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# print(\"policy_in_future:\", policy_in_future.shape)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Policy inference\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_in_past\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_in_future\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m u_first \u001b[38;5;241m=\u001b[39m u_pred[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     45\u001b[0m u_applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(inverse_normalize_x(u_first, dim_id\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m3\u001b[39m]))  \u001b[38;5;66;03m# laser power\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/github/DPC_research/02_DED/5_policy_0728_onehotencoding/policy.py:39\u001b[0m, in \u001b[0;36mPolicyNN.forward\u001b[0;34m(self, x_in)\u001b[0m\n\u001b[1;32m     36\u001b[0m past, future \u001b[38;5;241m=\u001b[39m x_in\n\u001b[1;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), future\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ln(x)\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x600 and 1400x1024)"
     ]
    }
   ],
   "source": [
    "# step #\n",
    "P = 50\n",
    "N_step = len(mp_temp_ref) - init_runs + 50\n",
    "\n",
    "\n",
    "# initialize GAMMA class\n",
    "GAMMA_class.ref = mp_temp_ref\n",
    "GAMMA_class.fix_cov_all = fix_covariates\n",
    "GAMMA_class.x_past = init_avg.clone()\n",
    "GAMMA_class.u_past = laser_power_past.clone()\n",
    "\n",
    "GAMMA_class.x_hat_current = GAMMA_class.x_past[:, -1]\n",
    "GAMMA_class.x_sys_current = GAMMA_class.x_past[:, -1].reshape(2, 1)\n",
    "\n",
    "GAMMA_class.x_past_save = GAMMA_class.x_past.T.clone()\n",
    "GAMMA_class.u_past_save = GAMMA_class.u_past.clone()\n",
    "GAMMA_class.MPC_counter = window \n",
    "GAMMA_class.z_all = loc_Z_list  # shape: [N, 1]\n",
    "\n",
    "\n",
    "# execution loop\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(N_step)):\n",
    "    run_one_step_policy(GAMMA_class, model, P=P, window=window)\n",
    "\n",
    "    if i % 300 == 0:\n",
    "        plot_fig(GAMMA_class, N_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f76198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
