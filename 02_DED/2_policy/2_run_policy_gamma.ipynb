{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fa2cc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Tuple\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from pickle import dump\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda is available\")\n",
    "else:\n",
    "    print(\"cuda is NOT available\")\n",
    "\n",
    "\n",
    "import shutil\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "from nn_functions import surrogate\n",
    "from moving_average import moving_average_1d\n",
    "import copy\n",
    "from GAMMA_obj_temp_depth import GAMMA_obj\n",
    "\n",
    "import sys\n",
    "sys.path.append('../1_model')\n",
    "from TiDE import TideModule, quantile_loss, TiDE_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec0ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 90/250 [00:03<00:05, 27.70it/s]"
     ]
    }
   ],
   "source": [
    "INPUT_DATA_DIR = \"data\"\n",
    "SIM_DIR_NAME = \"single_track_square\"\n",
    "BASE_LASER_FILE_DIR = \"laser_power_profiles/csv\"\n",
    "CLOUD_TARGET_BASE_PATH = \"result\"\n",
    "solidus_temp = 1600\n",
    "window = 50\n",
    "sim_interval = 5\n",
    "init_runs = 50 #50 \n",
    "\n",
    "GAMMA_class = GAMMA_obj(INPUT_DATA_DIR, SIM_DIR_NAME, BASE_LASER_FILE_DIR, CLOUD_TARGET_BASE_PATH, solidus_temp, window, init_runs, sim_interval,laser_power_number=1)\n",
    "init_avg = GAMMA_class.run_initial_steps()\n",
    "init_avg = torch.tensor(init_avg,dtype=torch.float32)[:,-window:] # shape = [2,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52950edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_print = pd.read_csv('single_track_ref.csv')\n",
    "\n",
    "loc_X_list = df_one_print[\"X\"].to_numpy().reshape(-1,1)\n",
    "loc_Y_list = df_one_print[\"Y\"].to_numpy().reshape(-1,1)\n",
    "loc_Z_list = df_one_print[\"Z\"].to_numpy().reshape(-1,1)\n",
    "dist_X_list = df_one_print[\"Dist_to_nearest_X\"].to_numpy().reshape(-1,1)\n",
    "dist_Y_list = df_one_print[\"Dist_to_nearest_Y\"].to_numpy().reshape(-1,1)\n",
    "scan_spd_list = df_one_print[\"scanning_speed\"].to_numpy().reshape(-1,1)\n",
    "\n",
    "# laser on/off indicator\n",
    "laser_on_off = df_one_print[\"laser_power_number\"].to_numpy().reshape(-1,1)\n",
    "\n",
    "# laser power\n",
    "laser_power_ref = torch.tensor(df_one_print[\"Laser_power\"].to_numpy().reshape(-1,1),dtype=torch.float32)\n",
    "laser_power_past = laser_power_ref[:window]\n",
    "\n",
    "# fix_covariates = torch.tensor(np.concatenate((loc_X_list,loc_Y_list,loc_Z_list,dist_X_list,dist_Y_list,scan_spd_list, laser_on_off),axis=1),dtype=torch.float32)\n",
    "fix_covariates = torch.tensor(np.concatenate((loc_Z_list,dist_X_list,dist_Y_list),axis=1),dtype=torch.float32)\n",
    "\n",
    "# temporary ref\n",
    "# apply moving average for mp temp\n",
    "mp_temp_raw = df_one_print[\"melt_pool_temperature\"].to_numpy()\n",
    "mp_temp_mv = moving_average_1d(mp_temp_raw,4)\n",
    "mp_temp = copy.deepcopy(mp_temp_raw)\n",
    "mp_temp[1:-2] = mp_temp_mv\n",
    "mp_temp = mp_temp\n",
    "\n",
    "mp_temp_ref = torch.tensor(mp_temp,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c693cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laser_power_ref shape: torch.Size([6295, 1])\n",
      "laser_power_ref min: 531.5235595703125\n",
      "laser_power_ref max: 600.7783203125\n",
      "fix_covariates shape: torch.Size([6295, 3])\n",
      "fix_covariates column-wise min: [0.   0.75 0.75]\n",
      "fix_covariates column-wise max: [ 7.5 20.  20. ]\n",
      "NaN indices: tensor([6292, 6294])\n",
      "mp_temp_ref (valid) min: 436.1014099121094\n",
      "mp_temp_ref (valid) max: 3834.751220703125\n"
     ]
    }
   ],
   "source": [
    "print(\"laser_power_ref shape:\", laser_power_ref.size())\n",
    "print(\"laser_power_ref min:\", torch.min(laser_power_ref).item())\n",
    "print(\"laser_power_ref max:\", torch.max(laser_power_ref).item())\n",
    "\n",
    "print(\"fix_covariates shape:\", fix_covariates.size())\n",
    "\n",
    "col_min = torch.min(fix_covariates, dim=0).values\n",
    "col_max = torch.max(fix_covariates, dim=0).values\n",
    "\n",
    "print(\"fix_covariates column-wise min:\", col_min.cpu().numpy())\n",
    "print(\"fix_covariates column-wise max:\", col_max.cpu().numpy())\n",
    "\n",
    "nan_indices = torch.nonzero(torch.isnan(mp_temp_ref), as_tuple=True)[0]\n",
    "print(\"NaN indices:\", nan_indices)\n",
    "\n",
    "valid_values = mp_temp_ref[~torch.isnan(mp_temp_ref)]\n",
    "\n",
    "print(\"mp_temp_ref (valid) min:\", valid_values.min().item())\n",
    "print(\"mp_temp_ref (valid) max:\", valid_values.max().item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d7cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# values from user\n",
    "x_min = torch.tensor([[0.0, 0.75, 0.75, 504.26]], dtype=torch.float32).to(device)\n",
    "x_max = torch.tensor([[7.5, 20.0, 20.0, 732.298]], dtype=torch.float32).to(device)\n",
    "\n",
    "y_min = torch.tensor([[436.608, -0.559]], dtype=torch.float32).to(device)\n",
    "y_max = torch.tensor([[4509.855, 0.551]], dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48581acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_x(x, dim_id):\n",
    "    x_min_selected = x_min[0, dim_id]\n",
    "    x_max_selected = x_max[0, dim_id]\n",
    "    return 2 * (x - x_min_selected) / (x_max_selected - x_min_selected) - 1\n",
    "\n",
    "def inverse_normalize_x(x_norm, dim_id):\n",
    "    x_min_selected = x_min[0, dim_id]\n",
    "    x_max_selected = x_max[0, dim_id]\n",
    "    return 0.5 * (x_norm + 1) * (x_max_selected - x_min_selected) + x_min_selected\n",
    "\n",
    "def normalize_y(y, dim_id):\n",
    "    y_min_selected = y_min[0, dim_id]\n",
    "    y_max_selected = y_max[0, dim_id]\n",
    "    return 2 * (y - y_min_selected) / (y_max_selected - y_min_selected) - 1\n",
    "\n",
    "def inverse_normalize_y(y_norm, dim_id):\n",
    "    y_min_selected = y_min[0, dim_id]\n",
    "    y_max_selected = y_max[0, dim_id]\n",
    "    return 0.5 * (y_norm + 1) * (y_max_selected - y_min_selected) + y_min_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_step_policy(GAMMA_obj, policy_model, P, window):\n",
    "    # Reference trajectory for temperature (original scale)\n",
    "    mp_temp_ref = GAMMA_obj.ref[GAMMA_obj.MPC_counter:GAMMA_obj.MPC_counter + P]  # [P, 1] or [P]\n",
    "    mp_temp_ref_t = torch.as_tensor(mp_temp_ref, dtype=torch.float32, device=device).reshape(1, P, 1)  # [1, P, 1]\n",
    "    # print(\"mp_temp_ref_t:\", mp_temp_ref_t.shape)\n",
    "\n",
    "    # Past input (original scale)\n",
    "    mp_temp_past_t = GAMMA_obj.x_past.T.unsqueeze(0).to(device)  # [1, 50, 2]\n",
    "    laser_past_t = GAMMA_obj.u_past.view(1, -1, 1).to(device)     # [1, 50, 1]\n",
    "\n",
    "    laser_past_t = 0 * laser_past_t  # This line is redundant, but kept for consistency with the original code\n",
    "    fix_cov_past = GAMMA_obj.fix_cov_all[GAMMA_obj.MPC_counter - window:GAMMA_obj.MPC_counter, :]\n",
    "    fix_cov_past_t = torch.as_tensor(fix_cov_past, dtype=torch.float32, device=device).unsqueeze(0)  # [1, 50, 3]\n",
    "\n",
    "    # print(\"mp_temp_past_t:\", mp_temp_past_t.shape)\n",
    "    # print(\"laser_past_t:\", laser_past_t.shape)\n",
    "    # print(\"fix_cov_past_t:\", fix_cov_past_t.shape)\n",
    "\n",
    "    # Normalize\n",
    "    fix_cov_past_s = normalize_x(fix_cov_past_t, dim_id=[0, 1, 2])    # assume features 0~2 in x\n",
    "    laser_past_s = normalize_x(laser_past_t, dim_id=[3])*0              # laser power at feature 3\n",
    "    mp_temp_past_s = normalize_y(mp_temp_past_t, dim_id=[0, 1])       # temp and depth\n",
    "    # print(\"mp_temp_past_s:\", mp_temp_past_s.squeeze(0).cpu().numpy())\n",
    "    # print(\"laser_past_s:\", laser_past_s.squeeze(0).cpu().numpy())\n",
    "    # print(\"fix_cov_past_s:\", fix_cov_past_s.squeeze(0).cpu().numpy())\n",
    "\n",
    "\n",
    "    policy_in_past = torch.cat((fix_cov_past_s, laser_past_s, mp_temp_past_s), dim=2)  # [1, 50, 6]\n",
    "    # print(\"policy_in_past:\", policy_in_past.shape)\n",
    "\n",
    "    # Future covariates\n",
    "    fix_cov_future = GAMMA_obj.fix_cov_all[GAMMA_obj.MPC_counter:GAMMA_obj.MPC_counter + P, :]\n",
    "    fix_cov_future_t = torch.as_tensor(fix_cov_future, dtype=torch.float32, device=device).unsqueeze(0)  # [1, P, 3]\n",
    "    fix_cov_future_s = normalize_x(fix_cov_future_t, dim_id=[0, 1, 2])\n",
    "    mp_temp_ref_s = normalize_y(mp_temp_ref_t, dim_id=[0])[:, :, 0].unsqueeze(-1)\n",
    "\n",
    "    # Constraints\n",
    "    depth_upper_const = 0.4126\n",
    "    depth_lower_const = 0.1423\n",
    "    y_const_t = torch.tensor([[depth_upper_const, depth_lower_const]] * P, dtype=torch.float32, device=device).reshape(1, P, 2)\n",
    "    y_const_s = normalize_y(y_const_t, dim_id=[1])  # assume dim=1 is depth\n",
    "\n",
    "    policy_in_future = torch.cat((fix_cov_future_s, mp_temp_ref_s, y_const_s), dim=2)  # [1, P, 6]\n",
    "    # print(\"policy_in_future:\", policy_in_future.shape)\n",
    "\n",
    "    # Policy inference\n",
    "    u_pred = policy_model((policy_in_past, policy_in_future))\n",
    "    u_first = u_pred[0,0]\n",
    "    u_applied = float(inverse_normalize_x(u_first, dim_id=[3]))  # laser power\n",
    "    # print(\"u_applied (original scale):\", u_applied)\n",
    "\n",
    "    # Simulate one step\n",
    "    x_current, depth_current = GAMMA_obj.run_sim_interval(u_applied)\n",
    "    # print(\"x_current, depth_current:\", x_current, depth_current)\n",
    "\n",
    "    # Update past sequence\n",
    "    GAMMA_obj.x_past[:, :-1] = GAMMA_obj.x_past[:, 1:]\n",
    "    GAMMA_obj.x_past[0, -1] = x_current\n",
    "    GAMMA_obj.x_past[1, -1] = depth_current\n",
    "\n",
    "    GAMMA_obj.u_past[:-1] = GAMMA_obj.u_past[1:].clone()\n",
    "    GAMMA_obj.u_past[-1] = u_applied\n",
    "\n",
    "    # Save state\n",
    "    # GAMMA_obj.x_hat_current = torch.tensor([x_current, depth_current], device=device)\n",
    "    # GAMMA_obj.x_sys_current = torch.tensor([[x_current], [depth_current]], device=device)\n",
    "    GAMMA_obj.MPC_counter += 1\n",
    "\n",
    "    # FIXED: device-matched saving\n",
    "    new_state = torch.tensor([[x_current, depth_current]], device=GAMMA_obj.x_past_save.device)\n",
    "    GAMMA_obj.x_past_save = torch.cat((GAMMA_obj.x_past_save, new_state), dim=0)\n",
    "\n",
    "    new_u = torch.tensor([[u_applied]], device=GAMMA_obj.u_past_save.device)\n",
    "    GAMMA_obj.u_past_save = torch.cat((GAMMA_obj.u_past_save, new_u), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_fig(MPC_GAMMA, N_step, save_path=None):\n",
    "    plt.figure(figsize=[8, 6])\n",
    "\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(MPC_GAMMA.x_past_save[:N_step, 0], label=\"GAMMA simulation\")\n",
    "    plt.plot(MPC_GAMMA.ref[:N_step], label=\"Reference\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"MPC time step (*** sec/iteration)\")\n",
    "    plt.ylabel(\"Melt Pool Temperature (K)\")\n",
    "\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(MPC_GAMMA.x_past_save[:N_step, 1], label=\"GAMMA simulation\")\n",
    "    plt.plot(np.linspace(0, N_step, N_step), 0.225 * np.ones(N_step), linestyle='--', label=\"Upper Bound\")\n",
    "    plt.plot(np.linspace(0, N_step, N_step), 0.075 * np.ones(N_step), linestyle='--', label=\"Lower Bound\")\n",
    "    plt.xlabel(\"MPC time step (*** sec/iteration)\")\n",
    "    plt.ylabel(\"Melt Pool Depth (mm)\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(MPC_GAMMA.u_past_save[:N_step])\n",
    "    plt.ylabel(\"Laser Power (W)\")\n",
    "    plt.xlabel(\"MPC time step (*** sec/iteration)\")\n",
    "    plt.xlim(0, N_step)\n",
    "\n",
    "    if save_path:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved plot to {save_path}\")\n",
    "    else:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b5c03",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ftk3187/github/DPC_research/02_DED/2_policy/trainresults/policy_model_0722_shift0.1_3L_1024H_s1_c1.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ftk3187/github/DPC_research/02_DED/2_policy/trainresults/policy_model_0722_shift0.1_3L_1024H_s1_c1.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# model_path = \"/home/ftk3187/github/DPC_research/02_DED/2_policy/trainresults/policy_model_0716_epoch100_3L_1024H_s2_c2.pth\"\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 초기화\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/dpc/lib/python3.11/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ftk3187/github/DPC_research/02_DED/2_policy/trainresults/policy_model_0722_shift0.1_3L_1024H_s1_c1.pth'"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import policy\n",
    "importlib.reload(policy)\n",
    "from policy import PolicyNN\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "P = 50\n",
    "window = 50\n",
    "N_step = len(mp_temp_ref) - P\n",
    "\n",
    "model = PolicyNN(\n",
    "    past_input_dim=6,\n",
    "    future_input_dim=6,\n",
    "    output_dim=1,\n",
    "    p=P,\n",
    "    window=window,\n",
    "    hidden_dim=1024,\n",
    "    n_layers=3,\n",
    "    dropout_p=0.1\n",
    ").to(device)\n",
    "\n",
    "model_path = \"/home/ftk3187/github/DPC_research/02_DED/2_policy/trainresults/policy_model_0722_shift0.1_3L_1024H_s1_c1.pth\"\n",
    "# model_path = \"/home/ftk3187/github/DPC_research/02_DED/2_policy/trainresults/policy_model_0716_epoch100_3L_1024H_s2_c2.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "# 초기화\n",
    "GAMMA_class.ref = mp_temp_ref.clone()\n",
    "GAMMA_class.fix_cov_all = fix_covariates.clone()\n",
    "GAMMA_class.x_past = init_avg.clone()\n",
    "GAMMA_class.u_past = laser_power_past.clone()\n",
    "\n",
    "GAMMA_class.x_hat_current = GAMMA_class.x_past[:, -1]\n",
    "GAMMA_class.x_sys_current = GAMMA_class.x_past[:, -1].reshape(2, 1)\n",
    "\n",
    "GAMMA_class.x_past_save = GAMMA_class.x_past.T.clone()\n",
    "GAMMA_class.u_past_save = GAMMA_class.u_past.clone()\n",
    "GAMMA_class.MPC_counter = window\n",
    "\n",
    "# 실행 루프\n",
    "for i in tqdm(range(N_step - P)):\n",
    "    run_one_step_policy(GAMMA_class, model, P=P, window=window)\n",
    "\n",
    "    # 원하는 구간마다 저장\n",
    "    if i % 1000 == 0:\n",
    "        plot_fig(GAMMA_class, N_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79129f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa4e67b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
